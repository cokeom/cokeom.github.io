<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hexo配置个人博客</title>
    <url>/2023/04/12/Hexo%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="Hexo配置个人博客"><a href="#Hexo配置个人博客" class="headerlink" title="Hexo配置个人博客"></a>Hexo配置个人博客</h1><p>本篇主要讲述配置过程中本人遇到的一些棘手问题。</p>
<p><strong>问题1：Github代码仓文件名对英文大小写不敏感</strong></p>
<p>我在根据网上的教程配置个人博客的<code>关于</code>页面时，发现无论我在本地怎么修改<code>about</code>文档或者配置文件，部署到Github上后打开总会出现404。而在本地检测(也就是<code>hexo s</code>)时却没有问题。</p>
<p>后面我发现导致这个问题是因为我修改了<code>about</code>文档名，本来我刚创建<code>about</code>文档时用的是大写字母<code>A</code>，也就是<code>About</code>。并且当时已经把相关<code>public</code>文件夹下的代码提交到了Github。然后我将<code>About</code>改为<code>about</code>后，将相关的配置文件的导向也改为了文件夹<code>about</code>，但是由于<strong>Github代码仓中的代码名对英文大小写不敏感</strong>，以至于上游代码文件夹名字一直没修改(<code>About</code>)。因此出现找不到页面的问题。</p>
<p>解决方案：先拷贝<code>about</code>文件夹。在本地将<code>about</code>文件夹删除，提交到上游。然后恢复<code>about</code>，再次提交即可。</p>
]]></content>
      <categories>
        <category>个人博客的配置</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA编程模型</title>
    <url>/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="CUDA编程模型"><a href="#CUDA编程模型" class="headerlink" title="CUDA编程模型"></a>CUDA编程模型</h1><p>CUDA，Compute Unified Device Architecture，计算同一设备架构。</p>
<img src="/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/image-20230305164943632.png" alt="image-20230305164943632" style="zoom:50%;">

<h2 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h2><p>编程模型指的是描述计算机程序中数据和算法之间交互的概念模型。通常包括程序的输入和输出、程序的组件以及它们之间的关系，以及程序的执行顺序和控制流程等方面。</p>
<p>例如面向对象编程模型是基于对象、类和继承等概念的模型，用于描述现实中的问题，使得程序的设计更为模块化和可拓展。</p>
<p>CUDA编程模型提供了一个计算机架构的抽象，作为应用程序和其可用硬件之间的桥梁。用于描述多个任务同时执行的计算机程序模型，在原有的并行编程模型的基础上，提供了以下两个特有功能：</p>
<ol>
<li>通过层次结构在GPU中组织线程</li>
<li>通过层次结构在GPU中访问内存</li>
</ol>
<p>CUDA编程模型使用由C语言扩展生成的注释代码在异构计算系统中执行应用程序。</p>
<p>在C语言并行编程中，需要使用pthreads或OpenMP技术来显式地管理线程。CUDA 提出了一个线程层次结构抽象的概念，以允许控制线程行为。这个抽象为并行编程提供了良好的可扩展性。</p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>CUDA是异构程序框架，对于一份运行的本地代码文件而言，其代码中有一部分是运行在CPU上，一部分运行在GPU上，这样的编程逻辑叫Kernel编程。相对应的，代码中用于在GPU上运行的代码称为核函数(Kernel function)。</p>
<p>核函数是在CUDA平台上执行的函数，由关键字”__global__”修饰，可以在设备上运行，也能从主机端调用。核函数一般通过线程块和线程索引进行调用和执行，并且可以在CUDA内核中使CUDA特定的之类和语法来利用GPU硬件资源。</p>
<p>一个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">vectorAdd</span><span class="params">(<span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">float</span> *c, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x; <span class="comment">// 利用线程块索引和线程索引进行设计算法</span></span><br><span class="line">    <span class="keyword">if</span> (i &lt; n) &#123;</span><br><span class="line">        c[i] = a[i] + b[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 初始化数据</span></span><br><span class="line">    <span class="type">int</span> n = <span class="number">10000</span>;</span><br><span class="line">    <span class="type">float</span> *a, *b, *c;</span><br><span class="line">    cudaMallocManaged(&amp;a, n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMallocManaged(&amp;b, n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMallocManaged(&amp;c, n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定义线程块大小和数量</span></span><br><span class="line">    <span class="type">int</span> blockSize = <span class="number">256</span>;</span><br><span class="line">    <span class="type">int</span> numBlocks = (n + blockSize - <span class="number">1</span>) / blockSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用CUDA核函数</span></span><br><span class="line">    vectorAdd&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(a, b, c, n);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待CUDA核函数执行完成</span></span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%f\n&quot;</span>, c[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放内存</span></span><br><span class="line">    cudaFree(a);</span><br><span class="line">    cudaFree(b);</span><br><span class="line">    cudaFree(c);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="NVIDIA-GPU硬件结构"><a href="#NVIDIA-GPU硬件结构" class="headerlink" title="NVIDIA GPU硬件结构"></a>NVIDIA GPU硬件结构</h2><p>GPU架构是围绕着一个叫做流式多处理器(SM，Streaming Multiprocessors)可拓展阵列构建而成。并且对于不同的GPU而言，其SM的结构可能不一样，下面是Fermi GPU架构下的SM组成：</p>
<img src="/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/image-20230307110304052.png" alt="image-20230307110304052" style="zoom:67%;">

<p>SM通常有下面几个部分组成：</p>
<ol>
<li>CUDA核心，又称SP(Streaming Processor)。一个SP可以执行一个thread，但是并不是所有的thread都可以在同一时刻执行。</li>
<li>共享内存&#x2F;L1 缓存</li>
<li>寄存器文件</li>
<li>加载存储单元</li>
<li>特殊函数单元(Special Function Units)</li>
<li>线程束调度器(Warp Scheduler)：</li>
</ol>
<p><strong>线程束：</strong>是SM中基本的执行单元。CUDA采用了SIMT架构来管理和执行线程，每32个线程为一组，称为线程束。线程束中的<strong>所有线程可以同时执行相同的指令</strong>，每个线程都有自己的<strong>地址计数器</strong>和<strong>寄存器状态</strong>。</p>
<p>GPU中每一个SM都可以支持数百个线程并发执行，每个GPU通常有多个SM，所以一个GPU可能并发执行数千个线程。当启动一个内核网络时，它的线程块被分布到了可用的SM上来执行。线程块一旦被调度到一个SM上，其中的线程只会在那个指定的SM上并发执行(多个线程块可能被分配到同一个SM上)。每个SM将分配它的线程块分到包含32个线程的线程束中。所有线程执行相同的指令，每个线程在私有数据上进行操作。</p>
<img src="/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/image-20230307150221390.png" alt="image-20230307150221390" style="zoom:50%;">

<p>下面是CUDA编程中软件与硬件对应关系：</p>
<img src="/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/image-20230307144733645.png" alt="image-20230307144733645" style="zoom:67%;">

<p>SIMT模型包含3个SIMD不具备的特征：</p>
<ol>
<li>每个线程都有自己的指令地址计数器</li>
<li>每个线程都有自己的寄存器状态</li>
<li>每个线程可以有一个独立的执行路径</li>
</ol>
<p>尽管线程块中所有线程可以逻辑地并行运行，但是并不是所有线程都可以同时在物理层面执行。因此，线程块里不同线程可能会以不同速度前进。</p>
<h2 id="内存层次结构"><a href="#内存层次结构" class="headerlink" title="内存层次结构"></a>内存层次结构</h2><p>CUDA内存模型提出了多种可编程内存的类型：</p>
<ul>
<li>寄存器</li>
<li>共享内存 shared memory</li>
<li>本地内存 Local memory</li>
<li>常量内存 Constant memory</li>
<li>纹理内存 Texture memory</li>
<li>全局内存 Global memory</li>
</ul>
<p>下图为这些内存空间的层次结构，每种内存都有不同的作用域、生命周期和缓存。</p>
<img src="/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/image-20230307163117953.png" alt="image-20230307163117953" style="zoom:67%;">

<p>一个核函数中的线程都有自己私有的本地内存(Local Memory)。</p>
<p>一个线程块有自己的共享内存(Shared Memory)，该内存对同一进程块中所有线程都可见，其内容持续线程块的整个生命周期。</p>
<p>所有线程都可以访问全局内存(Global Memory)。</p>
<p>所有线程都能访问的只读内存有：常量内存(Constant Memory)和纹理内存空间(Texture Memory)。纹理内存为各种数据分布提供了不同的寻址模式和滤波模式。</p>
<p>对于一个应用程序来说，全局内存、常量内存和纹理内存的内容具有相同的生命周期。</p>
<h2 id="线程层次结构"><a href="#线程层次结构" class="headerlink" title="线程层次结构"></a>线程层次结构</h2><p>CUDA通过对线程进行层次划分从而管理线程，该层次结构由线程块网络与线程块组成。</p>
<p><strong>线程</strong>：操作系统系统调度的最小单元。在CUDA编程模型下每个线程都有自己的一个块内的线程索引threadIdx，以及一个线程块索引blockIdx。线程索引可以描述为0~3维空间。例如threadldx为(x, y)时，表示线程在线程块中呈二维分布，可以用(x, y)来确定线程的具体(二维)位置。可以用threadIdx.x, threadIdx.y, threadIdx.z来指定三个维度的字段。</p>
<p>通常用blockDim表示每个线程块中线程的数量，也就是最大容量。例如blockDim为(16, 16, 1)时表示每个线程块中包含了16*16个线程。</p>
<p><strong>线程块</strong>：多个线程为一组，构成一个线程块。同一个线程块内部可以通过同步以及共享内存从而协作完成任务。描述线程块的变量为blockIdx，该变量可以描述为0~3维空间下的位置。例如blockIdx可以表示为(x, y, z)，表示线程块在线程块网络中的”三维位置”。可以用blockIdx.x, blockIdx.y, blockIdx.z来指定三个维度的字段。</p>
<p>通常用gridDim表示一个线程块网络中启动的线程块的数量，例如(64，64，1)表示启动了64*64 &#x3D; 4096个线程块。</p>
<p><strong>线程块网络</strong>：一个线程块网络由多个线程块组成，这些线程块共享相同的全局内存空间。不同块内部的线程不能协作。</p>
<img src="/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/image-20230306195537606.png" alt="image-20230306195537606" style="zoom:50%;">

<p>对于一个给定数据大小的情况，我们需要确定网络和块尺寸，一般步骤为：</p>
<ol>
<li>确定线程块大小</li>
<li>在已知数据大小和块大小的基础上计算网络维度</li>
</ol>
<p>在确定线程块大小时通常需要考虑：</p>
<ol>
<li>内核的性能特性</li>
<li>GPU资源限制</li>
</ol>
<p>下面这段代码是构建一个2x1x1大小的数据块网格(grid)以及3x1x1大小的数据块(block)，6个处理元素对应6个线程。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">checkIndex</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;threadIdx:(%d, %d, %d)   blockIdx:(%d, %d, %d)   blockDim:(%d, %d, %d)   gridDim:(%d, %d, %d)\n&quot;</span>,</span><br><span class="line">        threadIdx.x, threadIdx.y, threadIdx.z, blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, blockDim.z,</span><br><span class="line">        gridDim.x, gridDim.y, gridDim.z);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> &#123;</span><br><span class="line">  <span class="type">int</span> nElem = <span class="number">6</span>;</span><br><span class="line">  dim3 <span class="title function_">block</span><span class="params">(<span class="number">3</span>)</span>;</span><br><span class="line">  dim3 <span class="title function_">grid</span><span class="params">((nElem + block.x - <span class="number">1</span>) / block.x)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;grid.x %d, grid.y %d, grid.z %d\n&quot;</span>, grid.x, grid.y, grid.z);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;block.x %d, block.y %d, block.z %d\n&quot;</span>, block.x, block.y, block.z);</span><br><span class="line"></span><br><span class="line">  checkIndex &lt;&lt;&lt;grid, block&gt;&gt;&gt; ();</span><br><span class="line"></span><br><span class="line">  cudaDeviceReset();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行结果如下：</p>
<p><img src="/2023/04/12/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/image-20230306203929017.png" alt="image-20230306203929017"></p>
<p>该结果是由6个线程打印得出，分别打印其线程索引，线程块索引，线程块维度，线程块维度。</p>
<h3 id="使用块和线程建立索引"><a href="#使用块和线程建立索引" class="headerlink" title="使用块和线程建立索引"></a>使用块和线程建立索引</h3><h3 id="例子：计算矩阵加法"><a href="#例子：计算矩阵加法" class="headerlink" title="例子：计算矩阵加法"></a>例子：计算矩阵加法</h3><h4 id="使用二维网络和二维线程块"><a href="#使用二维网络和二维线程块" class="headerlink" title="使用二维网络和二维线程块"></a>使用二维网络和二维线程块</h4><h4 id="使用一维网络和一维线程块"><a href="#使用一维网络和一维线程块" class="headerlink" title="使用一维网络和一维线程块"></a>使用一维网络和一维线程块</h4><h4 id="使用二维网络和一维线程块"><a href="#使用二维网络和一维线程块" class="headerlink" title="使用二维网络和一维线程块"></a>使用二维网络和一维线程块</h4><hr>
<p>CUDA编程模型结构</p>
<ol>
<li>分配GPU内存</li>
<li>从CPU内存拷贝数据到GPU内存</li>
<li>调用CUDA内核函数来完成程序指定运算</li>
<li>将数据从GPU拷贝回CPU内存</li>
<li>释放GPU内存空间</li>
</ol>
<p>CUDA编程模型</p>
<p>编程结构</p>
<p>在一个异构环境中包含多个CPU和GPU，每个GPU和CPU的内存都由一条PCI-Express总线分隔开。</p>
<p>主机内存：CPU及其内存</p>
<p>设备内存：GPU及其内存</p>
<p>从CUDA 6.0开始，NVIDIA提出了统一寻址的编程模型的改进，它连接了主机内存和设备内存空间，可以使用单个指针访问CPU和GPU内存，无需彼此拷贝数据。</p>
]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>编程框架</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/04/11/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
</search>
